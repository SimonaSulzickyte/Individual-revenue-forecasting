{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for the 4th Quarter of 2022 - Recurring customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predictions of revenues with the clustering and without the clustering of customers. For the predictions without the clustering, the XGBoost model is trained on all data from the 1st Quarter of 2019 until the 3rd Quarter of 2022 and used to generate predictions for the 4th Quarter of 2022. For the predictions with clustering, separate XGBoost models are trained for each cluster on data from the 1st Quarter of 2019 until the 3rd Quarter of 2022 and used to generate predictions for the 4th Quarter of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data\n",
    "with open('Data final//data_recurring_imputed.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X = data.drop([\"Total_revenue\"], axis = \"columns\")\n",
    "y = data[\"Total_revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "xgb = XGBRegressor(subsample = 0.9, objective = 'reg:squarederror', n_estimators = 200, min_child_weight = 2, \n",
    "                    max_depth = 6, gamma = 0.1, eta = 0.3, colsample_bytree = 0.8, booster = 'gbtree')\n",
    "  \n",
    "# Fit the model\n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test data\n",
    "with open('data_recurring_test.pkl', 'rb') as file:\n",
    "    data_recurring_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data to have the columns in the same order\n",
    "data_recurring_test = data_recurring_test.to_numpy()\n",
    "column_names_recurring = [\"Number of accounts\", \"Age\", \"Longevity\", \"Insurance\", \"Total revenue\", \"Loan extensions\", \"Co-applicant\", \n",
    "                \"Invoice accounts\", \"Buy-now-pay-later\", \"Credit cards A\", \n",
    "                \"Credit cards B\", \"Credit cards C\", \"Consumer loans\", \"Default probability\", \n",
    "                \"Minimum limit\", \"Maximum limit\", \"Minimum balance\", \"Maximum balance\", \"Late payment\",\n",
    "                \"Number of transactions\", \"Exchange rate\", \"GDP growth\", \"Inflation\", \"Unemployment rate\",\n",
    "                \"Consumer confidence index\", \"Consumption of durables\", \"Interest rate\", \"Gender\",\n",
    "                \"Quarter_2\", \"Quarter_3\", \"Quarter_4\"]\n",
    "data_recurring_test = pd.DataFrame(np.row_stack(data_recurring_test), columns = column_names_recurring)\n",
    "data_recurring_test[\"Quarter_3\"] = 0 \n",
    "data_recurring_test[\"Quarter_4\"] = 1\n",
    "# Remove rows where default probability is missing\n",
    "data_recurring_test = data_recurring_test.loc[-data_recurring_test[\"Default probability\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X_test = data_recurring_test.drop([\"Total revenue\"], axis = \"columns\")\n",
    "y_test = data_recurring_test[\"Total revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test data\n",
    "pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "mean_squared_error(y_test, pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test data\n",
    "with open(\"data_recurring_test.pkl\", \"rb\") as file:\n",
    "    data_recurring_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data to have the columns in the same order\n",
    "data_recurring_test = data_recurring_test.to_numpy()\n",
    "column_names_recurring = [\"Number of accounts\", \"Age\", \"Longevity\", \"Insurance\", \"Total revenue\", \"Loan extensions\", \"Co-applicant\", \n",
    "                \"Invoice accounts\", \"Buy-now-pay-later\", \"Credit cards A\", \n",
    "                \"Credit cards B\", \"Credit cards C\", \"Consumer loans\", \"Default probability\", \n",
    "                \"Minimum limit\", \"Maximum limit\", \"Minimum balance\", \"Maximum balance\", \"Late payment\",\n",
    "                \"Number of transactions\", \"Exchange rate\", \"GDP growth\", \"Inflation\", \"Unemployment rate\",\n",
    "                \"Consumer confidence index\", \"Consumption of durables\", \"Interest rate\", \"Gender\",\n",
    "                \"Quarter_2\", \"Quarter_3\", \"Quarter_4\"]\n",
    "data_recurring_test = pd.DataFrame(np.row_stack(data_recurring_test), columns = column_names_recurring)\n",
    "data_recurring_test[\"Quarter_3\"] = 0 \n",
    "data_recurring_test[\"Quarter_4\"] = 1\n",
    "# Remove rows where default probability is missing\n",
    "data_recurring_test = data_recurring_test.loc[-data_recurring_test[\"Default probability\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted clusters\n",
    "with open(\"data_recurring_test_clusters.pkl\", \"rb\") as file:\n",
    "    data_recurring_test_clusters = pickle.load(file)\n",
    "\n",
    "# Add predicted clusters to the test data \n",
    "data_recurring_test[\"Predicted_cluster\"] = data_recurring_test_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for random search\n",
    "params = {\n",
    "    'n_estimators':[70, 100, 200],\n",
    "    'min_child_weight':[1, 2, 3], \n",
    "    'gamma':[i/10.0 for i in range(0,3)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,5,6,7],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'booster': ['gbtree'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "reg = XGBRegressor(nthread=-1)\n",
    "\n",
    "n_iter_search = 50\n",
    "\n",
    "random_search = RandomizedSearchCV(reg, param_distributions=params,\n",
    "                                   n_iter=n_iter_search, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted clusters \n",
    "with open('data_recurring_clusters_low.pkl', 'rb') as file:\n",
    "    data_low = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columnn of clusters\n",
    "data_low = data_low.drop([\"Cluster\"], axis = \"columns\")\n",
    "# Change column names\n",
    "data_low = data_low.to_numpy()\n",
    "column_names_recurring = [\"Number of accounts\", \"Age\", \"Longevity\", \"Insurance\", \"Total revenue\", \"Loan extensions\", \"Co-applicant\", \n",
    "                \"Invoice accounts\", \"Buy-now-pay-later\", \"Credit cards A\", \n",
    "                \"Credit cards B\", \"Credit cards C\", \"Consumer loans\", \"Default probability\", \n",
    "                \"Minimum limit\", \"Maximum limit\", \"Minimum balance\", \"Maximum balance\", \"Late payment\",\n",
    "                \"Number of transactions\", \"Exchange rate\", \"GDP growth\", \"Inflation\", \"Unemployment rate\",\n",
    "                \"Consumer confidence index\", \"Consumption of durables\", \"Interest rate\", \"Gender\",\n",
    "                \"Quarter_2\", \"Quarter_3\", \"Quarter_4\"]\n",
    "data_low = pd.DataFrame(np.row_stack(data_low), columns = column_names_recurring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X = data_low.drop([\"Total revenue\"], axis = \"columns\")\n",
    "y = data_low[\"Total revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a random search for low revenue cluster\n",
    "random_search.fit(X, y)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "xgb = XGBRegressor(subsample = 0.9, objective = 'reg:squarederror', n_estimators = 200, min_child_weight = 1, \n",
    "                    max_depth = 7, gamma = 0, eta = 0.3, colsample_bytree = 1, booster = 'gbtree')\n",
    "  \n",
    "# Fit the model\n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter customers with predicted low revenues\n",
    "data_recurring_test_low = data_recurring_test.loc[data_recurring_test[\"Predicted_cluster\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "data_recurring_test_low_X = data_recurring_test_low.drop([\"Predicted_cluster\", \"Total revenue\"], axis = \"columns\")\n",
    "data_recurring_test_low_y = data_recurring_test_low[\"Total revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict revenue\n",
    "pred = xgb.predict(data_recurring_test_low_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted revenues\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(pred, file)\n",
    "# Save real revenues \n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(data_recurring_test_low_y, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted clusters \n",
    "with open('data_recurring_clusters_mid.pkl', 'rb') as file:\n",
    "    data_mid = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columnn of clusters\n",
    "data_mid = data_mid.drop([\"Cluster\"], axis = \"columns\")\n",
    "# Change column names\n",
    "data_mid = data_mid.to_numpy()\n",
    "data_mid = pd.DataFrame(np.row_stack(data_mid), columns = column_names_recurring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X = data_mid.drop([\"Total revenue\"], axis = \"columns\")\n",
    "y = data_mid[\"Total revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a random search for middle revenue cluster\n",
    "random_search.fit(X, y)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "xgb = XGBRegressor(subsample = 0.9, objective = 'reg:squarederror', n_estimators = 200, min_child_weight = 3, \n",
    "                    max_depth = 7, gamma = 0.1, eta = 0.3, colsample_bytree = 0.7, booster = 'gbtree')\n",
    "  \n",
    "# Fit the model\n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter customers with predicted low revenues\n",
    "data_recurring_test_mid = data_recurring_test.loc[data_recurring_test[\"Predicted_cluster\"] == 1]\n",
    "# Split data into dependent and independent variables\n",
    "data_recurring_test_mid_X = data_recurring_test_mid.drop([\"Predicted_cluster\", \"Total revenue\"], axis = \"columns\")\n",
    "data_recurring_test_mid_y = data_recurring_test_mid[\"Total revenue\"]\n",
    "# Predict revenue\n",
    "pred = xgb.predict(data_recurring_test_mid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predictions for low revenues\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'rb') as file:\n",
    "    pred_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join predictions for low and middle revenues\n",
    "pred_all_classes = np.concatenate([pred_all_classes, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted revenues\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(pred_all_classes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload real revenues for low revenue segment\n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'rb') as file:\n",
    "    y_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join real revenues for low and middle revenue segment\n",
    "y_all_classes = np.concatenate([y_all_classes, data_recurring_test_mid_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save real revenues for low and middle revenue segment\n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(y_all_classes, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted clusters \n",
    "with open('data_recurring_clusters_high.pkl', 'rb') as file:\n",
    "    data_high = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columnn of clusters\n",
    "data_high = data_high.drop([\"Cluster\"], axis = \"columns\")\n",
    "# Change column names\n",
    "data_high = data_high.to_numpy()\n",
    "data_high = pd.DataFrame(np.row_stack(data_high), columns = column_names_recurring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X = data_high.drop([\"Total revenue\"], axis = \"columns\")\n",
    "y = data_high[\"Total revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a random search for high revenue cluster\n",
    "random_search.fit(X, y)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "xgb = XGBRegressor(subsample = 1, objective = 'reg:squarederror', n_estimators = 200, min_child_weight = 2, \n",
    "                    max_depth = 7, gamma = 0.2, eta = 0.3, colsample_bytree = 0.8, booster = 'gbtree')\n",
    "  \n",
    "# Fit the model\n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter customers with predicted low revenues\n",
    "data_recurring_test_high = data_recurring_test.loc[data_recurring_test[\"Predicted_cluster\"] == 2]\n",
    "# Split data into dependent and independent variables\n",
    "data_recurring_test_high_X = data_recurring_test_high.drop([\"Predicted_cluster\", \"Total revenue\"], axis = \"columns\")\n",
    "data_recurring_test_high_y = data_recurring_test_high[\"Total revenue\"]\n",
    "# Predict revenue\n",
    "pred = xgb.predict(data_recurring_test_high_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predictions for low and middle revenues\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'rb') as file:\n",
    "    pred_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join predictions for low, middle and high revenues\n",
    "pred_all_classes = np.concatenate([pred_all_classes, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted revenues\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(pred_all_classes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload real revenues for low and middle revenue segment\n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'rb') as file:\n",
    "    y_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join real revenues for low, middle and high revenue segment\n",
    "y_all_classes = np.concatenate([y_all_classes, data_recurring_test_high_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save real revenues for low, middle and high revenue segment\n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(y_all_classes, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted revenues for all clusters\n",
    "with open('data_recurring_clusters_test_predictions_XGB_all_classes.pkl', 'rb') as file:\n",
    "    pred_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload real revenues for all clusters\n",
    "with open('data_recurring_clusters_test_predictions_XGB_y_all_classes.pkl', 'rb') as file:\n",
    "    y_all_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "mean_absolute_error(y_all_classes, pred_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mean_squared_error(y_all_classes, pred_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "mean_squared_error(y_all_classes, pred_all_classes, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
